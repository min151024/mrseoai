import pandas as pd
from datetime import datetime, timedelta
from urllib.parse import urlparse
from serp_api_utils import get_top_competitor_urls, get_meta_info_from_url
from chatgpt_utils import build_prompt, get_chatgpt_response
from ga_utils import fetch_ga_conversion_for_url
from gsc_utils import get_search_console_service, fetch_gsc_data
from sheet_utils import (
    get_spreadsheet,
    get_or_create_worksheet,
    update_sheet
)

SPREADSHEET_ID = '1Fpdb-3j89j7OkPmJXbdmSmFBaA6yj2ZB0AUBNvF6BQ4'

def extract_path_from_url(full_url: str) -> str:
    parsed_url = urlparse(full_url)
    return parsed_url.path or "/"

def process_seo_improvement(site_url):
    print(f"\U0001F680 SEOæ”¹å–„ã‚’é–‹å§‹: {site_url}")

    today = datetime.today().date()
    yesterday = today - timedelta(days=1)

    this_week_start = yesterday - timedelta(days=6)
    this_week_end = yesterday

    last_week_start = yesterday - timedelta(days=13)
    last_week_end = yesterday - timedelta(days=7)

    service = get_search_console_service()
    df_this_week = fetch_gsc_data(service, site_url, this_week_start, this_week_end)
    df_last_week = fetch_gsc_data(service, site_url, last_week_start, last_week_end)

    if df_this_week.empty:
        print("âš ï¸ ä»Šé€±ã®GSCãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
        return "<p>ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚æ”¹å–„ææ¡ˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚</p>"

    ga_conversion_data = []
    for url in df_this_week["URL"].unique():
        ga_df = fetch_ga_conversion_for_url(
            start_date=this_week_start.isoformat(),
            end_date=this_week_end.isoformat(),
            full_url=url
        )
        if not ga_df.empty:
            ga_conversion_data.append(ga_df.iloc[0])

    if ga_conversion_data:
        ga_df_combined = pd.DataFrame(ga_conversion_data)
    else:
        ga_df_combined = pd.DataFrame(columns=["URL", "ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"])

    merged_df = pd.merge(df_this_week, ga_df_combined, on="URL", how="left")
    merged_df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"] = merged_df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"].fillna(0).astype(int)

    spreadsheet = get_spreadsheet(SPREADSHEET_ID)
    sheet_result = get_or_create_worksheet(spreadsheet, "SEOãƒ‡ãƒ¼ã‚¿")
    update_sheet(sheet_result, merged_df.columns.tolist(), merged_df.values.tolist())

    print("âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚")

    merged_compare = pd.merge(df_last_week, df_this_week, on='URL', suffixes=('_å…ˆé€±', '_ä»Šé€±'))
    merged_compare['é †ä½å¤‰åŒ–'] = merged_compare['å¹³å‡é †ä½_ä»Šé€±'] - merged_compare['å¹³å‡é †ä½_å…ˆé€±']
    dropped_df = merged_compare[merged_compare['é †ä½å¤‰åŒ–'] > 0].sort_values(by='é †ä½å¤‰åŒ–', ascending=False)

    if dropped_df.empty:
        print("âŒ é †ä½ãŒä¸‹ãŒã£ãŸãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return "<p>é †ä½ãŒä¸‹ãŒã£ãŸãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</p>"

    worst_page = dropped_df.iloc[0]
    target_url = worst_page['URL']
    print(f"ğŸ¯ å¯¾è±¡ãƒšãƒ¼ã‚¸: {target_url}")

    try:
        meta_info = get_meta_info_from_url(target_url)
        keyword = meta_info.get("title") or meta_info.get("description") or "SEO"
        print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
    except Exception as e:
        print(f"âš ï¸ ãƒ¡ã‚¿æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
        keyword = "SEO"

    try:
        top_urls = get_top_competitor_urls(keyword)
        competitors_info = [get_meta_info_from_url(url) for url in top_urls if url]
    except Exception as e:
        print(f"âš ï¸ ç«¶åˆãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—: {e}")
        competitors_info = []

    try:
        prompt = build_prompt(target_url, competitors_info)
        response = get_chatgpt_response(prompt)
        print("ğŸ’¡ ChatGPTæ”¹å–„æ¡ˆ:", response)
    except Exception as e:
        print(f"âš ï¸ ChatGPTã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {e}")
        response = "ChatGPT ã‹ã‚‰ã®æ”¹å–„ææ¡ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    result_html = f"""
    <!DOCTYPE html>
    <html lang=\"ja\">
    <head>
        <meta charset=\"UTF-8\">
        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">
        <title>SEO æ”¹å–„ææ¡ˆ</title>
    </head>
    <body>
        <h2>SEO æ”¹å–„ææ¡ˆ</h2>
        <p><strong>å¯¾è±¡URLï¼š</strong> {target_url}</p>
        <h3>ğŸ’¡ ChatGPTã®æ”¹å–„ææ¡ˆ</h3>
        <p>{response}</p>
        <a href=\"/\">æˆ»ã‚‹</a>
    </body>
    </html>
    """

    with open("templates/result.html", "w", encoding="utf-8") as f:
        f.write(result_html)

    print("âœ… HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

    return result_html

if __name__ == "__main__":
    process_seo_improvement("sc-domain:mrseoai.com")