
import pandas as pd
from datetime import datetime, timedelta
from serp_api_utils import get_top_competitor_urls, get_meta_info_from_url
from chatgpt_utils import build_prompt, get_chatgpt_response
from ga_utils import fetch_ga_data
from gsc_utils import get_search_console_service, fetch_gsc_data
from sheet_utils import (
    get_spreadsheet,
    get_or_create_worksheet,
    update_sheet,
    write_gsc_data_to_sheet,
    write_ga_data_to_sheet
)

SPREADSHEET_ID = '1Fpdb-3j89j7OkPmJXbdmSmFBaA6yj2ZB0AUBNvF6BQ4'

def process_seo_improvement(site_url):
    print(f"ğŸš€ SEOæ”¹å–„ã‚’é–‹å§‹: {site_url}")

    today = datetime.today().date()
    this_week_start = today - timedelta(days=7)
    this_week_end = today
    last_week_start = today - timedelta(days=14)
    last_week_end = today - timedelta(days=7)

    service = get_search_console_service()
    df_this_week = fetch_gsc_data(service, site_url, this_week_start, this_week_end)
    df_last_week = fetch_gsc_data(service, site_url, last_week_start, last_week_end)

    print("last_week rows:", len(df_last_week))
    print("this_week rows:", len(df_this_week))
    print(df_this_week.head())

    spreadsheet = get_spreadsheet(SPREADSHEET_ID)
    sheet_suggestions = get_or_create_worksheet(spreadsheet, "æ”¹å–„æ¡ˆ")
    update_sheet(sheet_suggestions, ['URL', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'è¡¨ç¤ºå›æ•°', 'CTRï¼ˆ%ï¼‰', 'å¹³å‡é †ä½'], df_this_week.values.tolist())

    gsc_data_for_export = []
    for _, row in df_this_week.iterrows():
        gsc_data_for_export.append({
            "url": row["URL"],
            "query": "ï¼ˆä»®ï¼‰",
            "position": row["å¹³å‡é †ä½"],
            "clicks": row["ã‚¯ãƒªãƒƒã‚¯æ•°"],
            "impressions": row["è¡¨ç¤ºå›æ•°"]
        })

    merged_df = pd.merge(df_last_week, df_this_week, on='URL', suffixes=('_å…ˆé€±', '_ä»Šé€±'))
    merged_df['é †ä½å¤‰åŒ–'] = merged_df['å¹³å‡é †ä½_ä»Šé€±'] - merged_df['å¹³å‡é †ä½_å…ˆé€±']
    dropped_df = merged_df[merged_df['é †ä½å¤‰åŒ–'] > 0].sort_values(by='é †ä½å¤‰åŒ–', ascending=False)

    sheet_dropped = get_or_create_worksheet(spreadsheet, "é †ä½ãŒä¸‹ãŒã£ãŸãƒšãƒ¼ã‚¸")
    update_sheet(sheet_dropped, ['URL', 'å¹³å‡é †ä½ï¼ˆå…ˆé€±ï¼‰', 'å¹³å‡é †ä½ï¼ˆä»Šé€±ï¼‰', 'é †ä½å¤‰åŒ–'],
                 dropped_df[['URL', 'å¹³å‡é †ä½_å…ˆé€±', 'å¹³å‡é †ä½_ä»Šé€±', 'é †ä½å¤‰åŒ–']].values.tolist())

    if dropped_df.empty:
        print("âŒ é †ä½ãŒä¸‹ãŒã£ãŸãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    all_df = pd.merge(df_last_week, df_this_week, on='URL', suffixes=('_å…ˆé€±', '_ä»Šé€±'))
    if all_df.empty:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã¾ã£ãŸãå­˜åœ¨ã—ãªã„ãŸã‚ã€æ”¹å–„å¯¾è±¡ãƒšãƒ¼ã‚¸ã‚’é¸ã¹ã¾ã›ã‚“ã€‚")
        return "<p>ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚æ”¹å–„ææ¡ˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚</p>"

    worst_page = all_df.sort_values(by='å¹³å‡é †ä½_ä»Šé€±', ascending=False).iloc[0]
    target_url = worst_page['URL']
    print(f"ğŸ¯ å¯¾è±¡ãƒšãƒ¼ã‚¸: {target_url}")

    try:
        meta_info = get_meta_info_from_url(target_url)
        keyword = meta_info.get("title") or meta_info.get("description") or "SEO"
        print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
    except Exception as e:
        print(f"âš ï¸ ãƒ¡ã‚¿æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
        return

    try:
        top_urls = get_top_competitor_urls(keyword)
        competitors_info = [get_meta_info_from_url(url) for url in top_urls if url]
    except Exception as e:
        print(f"âš ï¸ ç«¶åˆãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—: {e}")
        competitors_info = []

    try:
        prompt = build_prompt(target_url, competitors_info)
        response = get_chatgpt_response(prompt)
        print("ğŸ’¡ ChatGPTæ”¹å–„æ¡ˆ:", response)
    except Exception as e:
        print(f"âš ï¸ ChatGPTã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {e}")
        response = "ChatGPT ã‹ã‚‰ã®æ”¹å–„ææ¡ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    result_html = f"""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>SEO æ”¹å–„ææ¡ˆ</title>
    </head>
    <body>
        <h2>SEO æ”¹å–„ææ¡ˆ</h2>
        <p><strong>å¯¾è±¡URLï¼š</strong> {target_url}</p>
        <h3>ğŸ’¡ ChatGPTã®æ”¹å–„ææ¡ˆ</h3>
        <p>{response}</p>
        <a href="/">æˆ»ã‚‹</a>
    </body>
    </html>
    """

    with open("templates/result.html", "w", encoding="utf-8") as f:
        f.write(result_html)

    print("âœ… HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

    write_gsc_data_to_sheet(spreadsheet, gsc_data_for_export)
    write_ga_data_to_sheet(spreadsheet, fetch_ga_data(this_week_start.isoformat(), this_week_end.isoformat()))

    return result_html

if __name__ == "__main__":
    process_seo_improvement("https://mrseoai.com")
